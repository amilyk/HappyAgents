{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxZT2ReGjogI/1JHzcSAgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilyk/HappyAgents/blob/main/Plan_And_Solve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())"
      ],
      "metadata": {
        "id": "WuC2TL3_B-Vg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !touch .env\n",
        "# !echo \"LLM_API_KEY='API-Keyæ¯”å¦‚zhipuçš„'\" >> .env\n",
        "# !echo \"LLM_MODEL_ID='glm-4'\" >> .env\n",
        "# !echo \"LLM_BASE_URL='https://open.bigmodel.cn/api/paas/v4'\" >> .env"
      ],
      "metadata": {
        "id": "q-uVdl3NCIwg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# è§„åˆ’å™¨æç¤ºè¯æ¨¡æ¿ï¼ˆåˆ†è§£ä»»åŠ¡ï¼‰"
      ],
      "metadata": {
        "id": "E3ExjPMNAVgv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gOTOLNra-nay"
      },
      "outputs": [],
      "source": [
        "PLANNER_PROMPT_TEMPLATE = \"\"\"\n",
        "ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„AIè§„åˆ’ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æå‡ºçš„å¤æ‚é—®é¢˜åˆ†è§£æˆä¸€ä¸ªç”±å¤šä¸ªç®€å•æ­¥éª¤ç»„æˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚\n",
        "è¯·ç¡®ä¿è®¡åˆ’ä¸­çš„æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€å¯æ‰§è¡Œçš„å­ä»»åŠ¡ï¼Œå¹¶ä¸”ä¸¥æ ¼æŒ‰ç…§é€»è¾‘é¡ºåºæ’åˆ—ã€‚\n",
        "ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªPythonåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªæè¿°å­ä»»åŠ¡çš„å­—ç¬¦ä¸²ã€‚\n",
        "\n",
        "é—®é¢˜: {question}\n",
        "\n",
        "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„è®¡åˆ’,```pythonä¸```ä½œä¸ºå‰åç¼€æ˜¯å¿…è¦çš„:\n",
        "```python\n",
        "[\"æ­¥éª¤1\", \"æ­¥éª¤2\", \"æ­¥éª¤3\", ...]\n",
        "```\n",
        "\"\"\"\n",
        "#è§’è‰²è®¾å®š\n",
        "#ä»»åŠ¡æè¿°ï¼ˆåˆ†è§£ä»»åŠ¡ï¼‰\n",
        "#æ ¼å¼çº¦æŸ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# è§„åˆ’å™¨"
      ],
      "metadata": {
        "id": "I7ynLhpfAnYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å‡å®š llm_client.py ä¸­çš„ HelloAgentsLLM ç±»å·²ç»å®šä¹‰å¥½\n",
        "# from llm_client import HelloAgentsLLM\n",
        "import ast\n",
        "\n",
        "class Planner:\n",
        "    def __init__(self, llm_client):\n",
        "        self.llm_client = llm_client\n",
        "\n",
        "    def plan(self, question: str) -> list[str]:\n",
        "        \"\"\"\n",
        "        æ ¹æ®ç”¨æˆ·é—®é¢˜ç”Ÿæˆä¸€ä¸ªè¡ŒåŠ¨è®¡åˆ’ã€‚\n",
        "        \"\"\"\n",
        "        prompt = PLANNER_PROMPT_TEMPLATE.format(question=question)\n",
        "\n",
        "        # ä¸ºäº†ç”Ÿæˆè®¡åˆ’ï¼Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªç®€å•çš„æ¶ˆæ¯åˆ—è¡¨\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "        print(\"--- æ­£åœ¨ç”Ÿæˆè®¡åˆ’ ---\")\n",
        "        # ä½¿ç”¨æµå¼è¾“å‡ºæ¥è·å–å®Œæ•´çš„è®¡åˆ’\n",
        "        response_text = self.llm_client.think(messages=messages) or \"\"\n",
        "\n",
        "        print(f\"âœ… è®¡åˆ’å·²ç”Ÿæˆ:\\n{response_text}\")\n",
        "\n",
        "        # è§£æLLMè¾“å‡ºçš„åˆ—è¡¨å­—ç¬¦ä¸²\n",
        "        try:\n",
        "            # æ‰¾åˆ°```pythonå’Œ```ä¹‹é—´çš„å†…å®¹\n",
        "            plan_str = response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
        "            # ä½¿ç”¨ast.literal_evalæ¥å®‰å…¨åœ°æ‰§è¡Œå­—ç¬¦ä¸²ï¼Œå°†å…¶è½¬æ¢ä¸ºPythonåˆ—è¡¨\n",
        "            plan = ast.literal_eval(plan_str)\n",
        "            return plan if isinstance(plan, list) else []\n",
        "        except (ValueError, SyntaxError, IndexError) as e:\n",
        "            print(f\"âŒ è§£æè®¡åˆ’æ—¶å‡ºé”™: {e}\")\n",
        "            print(f\"åŸå§‹å“åº”: {response_text}\")\n",
        "            return []\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è§£æè®¡åˆ’æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "04_fZUEnAdY2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ‰§è¡Œå™¨çš„æç¤ºæ¨¡æ¿"
      ],
      "metadata": {
        "id": "UYM1MWx4AQUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXECUTOR_PROMPT_TEMPLATE = \"\"\"\n",
        "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„AIæ‰§è¡Œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„è®¡åˆ’ï¼Œä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚\n",
        "ä½ å°†æ”¶åˆ°åŸå§‹é—®é¢˜ã€å®Œæ•´çš„è®¡åˆ’ã€ä»¥åŠåˆ°ç›®å‰ä¸ºæ­¢å·²ç»å®Œæˆçš„æ­¥éª¤å’Œç»“æœã€‚\n",
        "è¯·ä½ ä¸“æ³¨äºè§£å†³â€œå½“å‰æ­¥éª¤â€ï¼Œå¹¶ä»…è¾“å‡ºè¯¥æ­¥éª¤çš„æœ€ç»ˆç­”æ¡ˆï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–å¯¹è¯ã€‚\n",
        "\n",
        "# åŸå§‹é—®é¢˜:\n",
        "{question}\n",
        "\n",
        "# å®Œæ•´è®¡åˆ’:\n",
        "{plan}\n",
        "\n",
        "# å†å²æ­¥éª¤ä¸ç»“æœ:\n",
        "{history}\n",
        "\n",
        "# å½“å‰æ­¥éª¤:\n",
        "{current_step}\n",
        "\n",
        "è¯·ä»…è¾“å‡ºé’ˆå¯¹â€œå½“å‰æ­¥éª¤â€çš„å›ç­”:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RxZw6MT1_iyb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ‰§è¡Œå™¨"
      ],
      "metadata": {
        "id": "-ZqfubSLAqC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Executor:\n",
        "    def __init__(self, llm_client):\n",
        "        self.llm_client = llm_client\n",
        "\n",
        "    def execute(self, question: str, plan: list[str]) -> str:\n",
        "        \"\"\"\n",
        "        æ ¹æ®è®¡åˆ’ï¼Œé€æ­¥æ‰§è¡Œå¹¶è§£å†³é—®é¢˜ã€‚\n",
        "        \"\"\"\n",
        "        history = \"\" # ç”¨äºå­˜å‚¨å†å²æ­¥éª¤å’Œç»“æœçš„å­—ç¬¦ä¸²\n",
        "\n",
        "        print(\"\\n--- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\")\n",
        "\n",
        "        for i, step in enumerate(plan):\n",
        "            print(f\"\\n-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {i+1}/{len(plan)}: {step}\")\n",
        "\n",
        "            prompt = EXECUTOR_PROMPT_TEMPLATE.format(\n",
        "                question=question,\n",
        "                plan=plan,\n",
        "                history=history if history else \"æ— \", # å¦‚æœæ˜¯ç¬¬ä¸€æ­¥ï¼Œåˆ™å†å²ä¸ºç©º\n",
        "                current_step=step\n",
        "            )\n",
        "\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "            response_text = self.llm_client.think(messages=messages) or \"\"\n",
        "\n",
        "            # æ›´æ–°å†å²è®°å½•ï¼Œä¸ºä¸‹ä¸€æ­¥åšå‡†å¤‡\n",
        "            history += f\"æ­¥éª¤ {i+1}: {step}\\nç»“æœ: {response_text}\\n\\n\"\n",
        "\n",
        "            print(f\"âœ… æ­¥éª¤ {i+1} å·²å®Œæˆï¼Œç»“æœ: {response_text}\")\n",
        "\n",
        "        # å¾ªç¯ç»“æŸåï¼Œæœ€åä¸€æ­¥çš„å“åº”å°±æ˜¯æœ€ç»ˆç­”æ¡ˆ\n",
        "        final_answer = response_text\n",
        "        return final_answer\n"
      ],
      "metadata": {
        "id": "wzt2DfvcAGRT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# é€šç”¨LLMå®¢æˆ·ç«¯"
      ],
      "metadata": {
        "id": "q357Vd3lBui4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "from openai import OpenAI\n",
        "from typing import List, Dict\n",
        "\n",
        "# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\n",
        "# load_dotenv()\n",
        "\n",
        "class HelloAgentsLLM:\n",
        "    \"\"\"\n",
        "    ä¸ºæœ¬ä¹¦ \"Hello Agents\" å®šåˆ¶çš„LLMå®¢æˆ·ç«¯ã€‚\n",
        "    å®ƒç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ï¼Œå¹¶é»˜è®¤ä½¿ç”¨æµå¼å“åº”ã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚\n",
        "        \"\"\"\n",
        "        self.model = model or os.environ.get(\"LLM_MODEL_ID\")\n",
        "        apiKey = apiKey or os.environ.get(\"LLM_API_KEY\")\n",
        "        baseUrl = baseUrl or os.environ.get(\"LLM_BASE_URL\")\n",
        "        timeout = timeout or int(os.environ.get(\"LLM_TIMEOUT\", 60))\n",
        "\n",
        "        if not all([self.model, apiKey, baseUrl]):\n",
        "            raise ValueError(\"æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚\")\n",
        "\n",
        "        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)\n",
        "\n",
        "    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:\n",
        "        \"\"\"\n",
        "        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚\n",
        "        \"\"\"\n",
        "        print(f\"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...\")\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                temperature=temperature,\n",
        "                stream=True,\n",
        "            )\n",
        "\n",
        "            # å¤„ç†æµå¼å“åº”\n",
        "            print(\"âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\")\n",
        "            collected_content = []\n",
        "            for chunk in response:\n",
        "                content = chunk.choices[0].delta.content or \"\"\n",
        "                print(content, end=\"\", flush=True)\n",
        "                collected_content.append(content)\n",
        "            print()  # åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ\n",
        "            return \"\".join(collected_content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
        "            return None\n",
        "\n",
        "# --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---\n",
        "# if __name__ == '__main__':\n",
        "#     try:\n",
        "#         llmClient = HelloAgentsLLM()\n",
        "\n",
        "#         exampleMessages = [\n",
        "#             {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes Python code.\"},\n",
        "#             {\"role\": \"user\", \"content\": \"å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•\"}\n",
        "#         ]\n",
        "\n",
        "#         print(\"--- è°ƒç”¨LLM ---\")\n",
        "#         responseText = llmClient.think(exampleMessages)\n",
        "#         if responseText:\n",
        "#             print(\"\\n\\n--- å®Œæ•´æ¨¡å‹å“åº” ---\")\n",
        "#             print(responseText)\n",
        "\n",
        "#     except ValueError as e:\n",
        "#         print(e)\n",
        "\n",
        "\n",
        "# >>>\n",
        "# --- è°ƒç”¨LLM ---\n",
        "# ğŸ§  æ­£åœ¨è°ƒç”¨ xxxxxx æ¨¡å‹...\n",
        "# âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
        "# å¿«é€Ÿæ’åºæ˜¯ä¸€ç§éå¸¸é«˜æ•ˆçš„æ’åºç®—æ³•..."
      ],
      "metadata": {
        "id": "WCRI33qIByAd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan and Solveæ™ºèƒ½ä½“"
      ],
      "metadata": {
        "id": "54dhVpgDBkGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlanAndSolveAgent:\n",
        "    def __init__(self, llm_client):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼ŒåŒæ—¶åˆ›å»ºè§„åˆ’å™¨å’Œæ‰§è¡Œå™¨å®ä¾‹ã€‚\n",
        "        \"\"\"\n",
        "        self.llm_client = llm_client\n",
        "        self.planner = Planner(self.llm_client)\n",
        "        self.executor = Executor(self.llm_client)\n",
        "\n",
        "    def run(self, question: str):\n",
        "        \"\"\"\n",
        "        è¿è¡Œæ™ºèƒ½ä½“çš„å®Œæ•´æµç¨‹:å…ˆè§„åˆ’ï¼Œåæ‰§è¡Œã€‚\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- å¼€å§‹å¤„ç†é—®é¢˜ ---\\né—®é¢˜: {question}\")\n",
        "\n",
        "        # 1. è°ƒç”¨è§„åˆ’å™¨ç”Ÿæˆè®¡åˆ’\n",
        "        plan = self.planner.plan(question)\n",
        "\n",
        "        # æ£€æŸ¥è®¡åˆ’æ˜¯å¦æˆåŠŸç”Ÿæˆ\n",
        "        if not plan:\n",
        "            print(\"\\n--- ä»»åŠ¡ç»ˆæ­¢ --- \\næ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚\")\n",
        "            return\n",
        "\n",
        "        # 2. è°ƒç”¨æ‰§è¡Œå™¨æ‰§è¡Œè®¡åˆ’\n",
        "        final_answer = self.executor.execute(question, plan)\n",
        "\n",
        "        print(f\"\\n--- ä»»åŠ¡å®Œæˆ ---\\næœ€ç»ˆç­”æ¡ˆ: {final_answer}\")"
      ],
      "metadata": {
        "id": "Lv_AjS7RBL8_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ™ºèƒ½ä½“è°ƒç”¨"
      ],
      "metadata": {
        "id": "laUpLqTyCofM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  llm = HelloAgentsLLM()\n",
        "  planAndSolveAgent = PlanAndSolveAgent(llm)\n",
        "  query = \"ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœ?\"\n",
        "  planAndSolveAgent.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT8Gj4CkBomm",
        "outputId": "95328c2b-0b8b-43e7-9757-67f4c8714067"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- å¼€å§‹å¤„ç†é—®é¢˜ ---\n",
            "é—®é¢˜: ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœ?\n",
            "--- æ­£åœ¨ç”Ÿæˆè®¡åˆ’ ---\n",
            "ğŸ§  æ­£åœ¨è°ƒç”¨ glm-4 æ¨¡å‹...\n",
            "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
            "```python\n",
            "[\"è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨ä¸€æ•°é‡ * 2\",\n",
            " \"è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨äºŒæ•°é‡ - 5\",\n",
            " \"è®¡ç®—è¿™ä¸‰å¤©æ€»å…±å–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨ä¸€æ•°é‡ + å‘¨äºŒæ•°é‡ + å‘¨ä¸‰æ•°é‡\"]\n",
            "```\n",
            "âœ… è®¡åˆ’å·²ç”Ÿæˆ:\n",
            "```python\n",
            "[\"è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨ä¸€æ•°é‡ * 2\",\n",
            " \"è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨äºŒæ•°é‡ - 5\",\n",
            " \"è®¡ç®—è¿™ä¸‰å¤©æ€»å…±å–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨ä¸€æ•°é‡ + å‘¨äºŒæ•°é‡ + å‘¨ä¸‰æ•°é‡\"]\n",
            "```\n",
            "\n",
            "--- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\n",
            "\n",
            "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 1/3: è®¡ç®—å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨ä¸€æ•°é‡ * 2\n",
            "ğŸ§  æ­£åœ¨è°ƒç”¨ glm-4 æ¨¡å‹...\n",
            "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
            "30\n",
            "âœ… æ­¥éª¤ 1 å·²å®Œæˆï¼Œç»“æœ: 30\n",
            "\n",
            "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 2/3: è®¡ç®—å‘¨ä¸‰å–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨äºŒæ•°é‡ - 5\n",
            "ğŸ§  æ­£åœ¨è°ƒç”¨ glm-4 æ¨¡å‹...\n",
            "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
            "25\n",
            "âœ… æ­¥éª¤ 2 å·²å®Œæˆï¼Œç»“æœ: 25\n",
            "\n",
            "-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ 3/3: è®¡ç®—è¿™ä¸‰å¤©æ€»å…±å–å‡ºçš„è‹¹æœæ•°é‡ï¼šå‘¨ä¸€æ•°é‡ + å‘¨äºŒæ•°é‡ + å‘¨ä¸‰æ•°é‡\n",
            "ğŸ§  æ­£åœ¨è°ƒç”¨ glm-4 æ¨¡å‹...\n",
            "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
            "70\n",
            "âœ… æ­¥éª¤ 3 å·²å®Œæˆï¼Œç»“æœ: 70\n",
            "\n",
            "--- ä»»åŠ¡å®Œæˆ ---\n",
            "æœ€ç»ˆç­”æ¡ˆ: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jmooHeXDPwd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}