AI agent


智能体演化路径：
1.原始智能体没有记忆和预测能力，根据外部环境感知做出回应（比如恒温器，外界温度变化就降低或升高温度）
2.当无法感知到环境的时候，增加了状态（根据存在、速度、位置做出预测，World Model世界模型理解），作为初步记忆（隧道里看不到前方车辆，自动驾驶的汽车）
3.设定明确目标，主动围绕目标，预测接下来的做法，比如GPS，目标（到达公司）+世界模型（地图数据）+做出回应（AI搜索算法规划最优路线）
4.多目标权衡（基于效用智能体Utility Based Agent），如何做出回应？最大化期望效用（比如GPS中，耗油少，路线短，拥堵少）
5.不依赖于人类先验知识，通过与环境互动得到学习，智能体自己应对的一套规则，期望效用逻辑？学习型智能体（强化学习，奖励模型，比如AlphGo）

LLM大模型与传统智能体区别
1.大模型预训练，获得世界模型+涌现能力（应对复杂情况做出回应），而传统智能体依赖于工程师的编程能力（强化学习）

智能体分类
1.内部决策的复杂程度
   反应式、模型式、基于目标、基于效用
2.基于时间和决策
  反应式：反应、模型式（反应快，计算开销低）
  规划式智能体：基于目标、基于效用（优先探索可能性，而非立即反应）
  混合式智能体：即时反应（与环境交互获得反馈）+长期规划（分解任务，得到决策），比如旅行规划
3.基于知识
  符号主义：基于规则，逻辑推理
  亚符号主义：处理非结构化数据（直觉、模式识别），黑箱
  神经符号主义：符号主义+亚符号主义

智能体运行机制
Thought (根据与环境交互得到的决策方案)-> 
Action（具体决策通过调用函数实现） -> 
observation（action结果转成LLM能理解的自然语言）

开发工具的智能体
GitHubCopilot
Claude Code
Trae
Cursor（本身就是编辑器，而不是插件）

自主协作智能体（自我驱动型更强）
1.单智能体
2.多智能体协作（CrewAI、MetaGPT 和 AgentScope）
￼

传统的自然语言处理，难以从一个任务泛化到其他任务
预训练（海量通用知识库，自监督，训练超大规模模型） + 微调（特定领域，少量数据微调）

LLM的涌现能力
1.In-context learning: 0 shot, few shot 
2.Chain-of-Thought(引导模型回答问题前，输出推理过程)  


联结主义（神经网络，每个神经元做微小的事情，却能拥有感知世界的能力）
强化学习学会在与环境的交互中进行最优决策
大型语言模型（LLM）世界知识和通用推理能力。

N-gram
计算一个句子（每个词出现的条件概率的连乘）的概率，所有词条件概率太难从语料库中估计
马尔可夫假设，一个词出现的概率只与有限的n-1个词有关，N-gram模型
比如N-gram=2，假设一个词的出现只与前一个词有关。
比如N-gram=3，假设一个词的出现与前面2个词有关。
缺点：新词、泛化能力差（agent learns 与 robot learns相似，但无法扩展到robot learns，如果robot没出现过）

神经网络与词嵌入
1.词向量（语义相似，向量相近）
2.神经网络可以学习输入前n-1词向量，输出上下文窗口中每个词的概率分布
余弦相似度：余弦值1（角度0度，正相关）、余弦值0（角度90度，毫无关系）、余弦值-1（角度180度，负相关）

RNN为网络增加记忆能力（词嵌入上下文窗口固定，N-gram只能看到前N个词），当前的输入词，并结合它上一刻的记忆（即上一个时间步的隐藏状态），然后生成一个新的记忆
RNN无法解决长期依赖问题（反向传播时多次连乘，梯度消失或梯度爆炸） 
-> LSTM
* 遗忘门 (Forget Gate)：决定从上一时刻的细胞状态中丢弃哪些信息。
* 输入门 (Input Gate)：决定将当前输入中的哪些新信息存入细胞状态。
* 输出门 (Output Gate)：决定根据当前的细胞状态，输出哪些信息到隐藏状态。

Transformer:
RNN(顺序执行，无法并行)

LLM的参数
Top-k
Top-p
Temperature

Prompt技巧
0-shot one-shot few-shot 

Instruction FineTuning指令微调，大量“指令-回答”格式的数据微调（？）

In-context learning（类似于few shot的上下文案例）

CoT（Chain of Thought）：“请逐步思考”或“Let's think step by step”

字节对编码BPE
“贪心”的合并过程
1. 初始化：将词表初始化为所有在语料库中出现过的基本字符。
2. 迭代合并：在语料库上，统计所有相邻词元对的出现频率，找到频率最高的一对，将它们合并成一个新的词元，并加入词表。
3. 重复：重复第 2 步，直到词表大小达到预设的阈值。

幻觉
1. 数据层面： 通过高质量数据清洗、引入事实性知识以及强化学习与人类反馈 (RLHF) 等方式[13]，从源头减少幻觉。
2. 模型层面： 探索新的模型架构，或让模型能够表达其对生成内容的不确定性。
3. 推理与生成层面：
    1. 检索增强生成 (Retrieval-Augmented Generation, RAG) [14]： 这是目前缓解幻觉的有效方法之一。RAG 系统通过在生成之前从外部知识库（如文档数据库、网页）中检索相关信息，然后将检索到的信息作为上下文，引导模型生成基于事实的回答。
    2. 多步推理与验证： 引导模型进行多步推理，并在每一步进行自我检查或外部验证。
    3. 引入外部工具： 允许模型调用外部工具（如搜索引擎、计算器、代码解释器）来获取实时信息或进行精确计算。










