{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrlWTFnvyJjsHvUVndERUC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilyk/HappyAgents/blob/main/LanGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"langchain|langgraph\"\n",
        "!pip uninstall -y langchain langchain-core\n",
        "!pip install \"langchain>=0.3.35\" \"langgraph\""
      ],
      "metadata": {
        "id": "Ykd675e0b-zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai\n",
        "!pip install tavily-python"
      ],
      "metadata": {
        "id": "K6mxG0UvhOow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定义全局状态"
      ],
      "metadata": {
        "id": "h_3J8Y2qYfEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class SearchState(TypedDict):\n",
        "    messages: Annotated[list, add_messages] # 对话历史\n",
        "    user_query: str      # 经过LLM理解后的用户需求总结\n",
        "    search_query: str    # 优化后用于Tavily API的搜索查询\n",
        "    search_results: str  # Tavily搜索返回的结果\n",
        "    final_answer: str    # 最终生成的答案\n",
        "    step: str            # 标记当前步骤\n"
      ],
      "metadata": {
        "id": "ymvr3UJAYiT2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 节点定义"
      ],
      "metadata": {
        "id": "Ny9nMqDcZbuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !touch .env\n",
        "# !echo \"TAVILY_API_KEY='tvly-api-key'\" >> .env\n",
        "# !echo \"LLM_API_KEY=my-api-key\" >> .env"
      ],
      "metadata": {
        "id": "dNydBu-4eAPG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# 加载 .env 文件中的环境变量\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# 初始化模型\n",
        "# 我们将使用这个 llm 实例来驱动所有节点的智能\n",
        "# llm = ChatOpenAI(\n",
        "#     model=os.getenv(\"LLM_MODEL_ID\", \"gpt-4o-mini\"),\n",
        "#     api_key=os.getenv(\"LLM_API_KEY\"),\n",
        "#     base_url=os.getenv(\"LLM_BASE_URL\", \"https://api.openai.com/v1\"),\n",
        "#     temperature=0.7\n",
        "# )\n",
        "llm = ChatOpenAI(\n",
        "    model=os.getenv(\"LLM_MODEL_ID\", \"deepseek-chat\"),\n",
        "    api_key=os.getenv(\"LLM_API_KEY\"),\n",
        "    base_url=os.getenv(\"LLM_BASE_URL\", \"https://api.deepseek.com/v1\"),\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# 初始化Tavily客户端\n",
        "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
      ],
      "metadata": {
        "id": "RLvuNZm_cQ7A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 理解和查询节点"
      ],
      "metadata": {
        "id": "7mq33sqXfz1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#将用户意图改写成搜索关键词\n",
        "def understand_query_node(state: SearchState) -> SearchState:\n",
        "    \"\"\"步骤1：理解用户查询并生成搜索关键词\"\"\"\n",
        "\n",
        "    # 获取最新的用户消息\n",
        "    user_message = \"\"\n",
        "    for msg in reversed(state[\"messages\"]):\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            user_message = msg.content\n",
        "            break\n",
        "\n",
        "    understand_prompt = f\"\"\"分析用户的查询：\"{user_message}\"\n",
        "\n",
        "请完成两个任务：\n",
        "1. 简洁总结用户想要了解什么\n",
        "2. 生成最适合搜索的关键词（中英文均可，要精准）\n",
        "\n",
        "格式：\n",
        "理解：[用户需求总结]\n",
        "搜索词：[最佳搜索关键词]\"\"\"\n",
        "\n",
        "    response = llm.invoke([SystemMessage(content=understand_prompt)])\n",
        "\n",
        "    # 提取搜索关键词\n",
        "    response_text = response.content\n",
        "    search_query = user_message  # 默认使用原始查询\n",
        "\n",
        "    if \"搜索词：\" in response_text:\n",
        "        search_query = response_text.split(\"搜索词：\")[1].strip()\n",
        "    elif \"搜索关键词：\" in response_text:\n",
        "        search_query = response_text.split(\"搜索关键词：\")[1].strip()\n",
        "\n",
        "    return {\n",
        "        \"user_query\": response.content,\n",
        "        \"search_query\": search_query,\n",
        "        \"step\": \"understood\",\n",
        "        \"messages\": [AIMessage(content=f\"我理解您的需求：{response.content}\")]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "JOTkiFQ4fZu5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 搜索节点"
      ],
      "metadata": {
        "id": "22t7j2Gqf5ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#根据搜索关键词调用Tavily API\n",
        "def tavily_search_node(state: SearchState) -> SearchState:\n",
        "    \"\"\"步骤2：使用Tavily API进行真实搜索\"\"\"\n",
        "\n",
        "    search_query = state[\"search_query\"]\n",
        "\n",
        "    try:\n",
        "        print(f\"🔍 正在搜索: {search_query}\")\n",
        "\n",
        "        # 调用Tavily搜索API\n",
        "        response = tavily_client.search(\n",
        "            query=search_query,\n",
        "            search_depth=\"basic\",\n",
        "            include_answer=True,\n",
        "            include_raw_content=False,\n",
        "            max_results=5\n",
        "        )\n",
        "\n",
        "        # 处理搜索结果\n",
        "        search_results = \"\"\n",
        "\n",
        "        # 优先使用Tavily的综合答案\n",
        "        if response.get(\"answer\"):\n",
        "            search_results = f\"综合答案：\\n{response['answer']}\\n\\n\"\n",
        "\n",
        "        # 添加具体的搜索结果\n",
        "        if response.get(\"results\"):\n",
        "            search_results += \"相关信息：\\n\"\n",
        "            for i, result in enumerate(response[\"results\"][:3], 1):\n",
        "                title = result.get(\"title\", \"\")\n",
        "                content = result.get(\"content\", \"\")\n",
        "                url = result.get(\"url\", \"\")\n",
        "                search_results += f\"{i}. {title}\\n{content}\\n来源：{url}\\n\\n\"\n",
        "\n",
        "        if not search_results:\n",
        "            search_results = \"抱歉，没有找到相关信息。\"\n",
        "\n",
        "        return {\n",
        "            \"search_results\": search_results,\n",
        "            \"step\": \"searched\",\n",
        "            \"messages\": [AIMessage(content=f\"✅ 搜索完成！找到了相关信息，正在为您整理答案...\")]\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"搜索时发生错误: {str(e)}\"\n",
        "        print(f\"❌ {error_msg}\")\n",
        "\n",
        "        return {\n",
        "            \"search_results\": f\"搜索失败：{error_msg}\",\n",
        "            \"step\": \"search_failed\",\n",
        "            \"messages\": [AIMessage(content=\"❌ 搜索遇到问题，我将基于已有知识为您回答\")]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "RZFriCtDYiyE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 回答节点"
      ],
      "metadata": {
        "id": "7eQP-WEhgXLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_node(state: SearchState) -> SearchState:\n",
        "    \"\"\"步骤3：基于搜索结果生成最终答案\"\"\"\n",
        "\n",
        "    # 检查是否有搜索结果\n",
        "    if state[\"step\"] == \"search_failed\":\n",
        "        # 如果搜索失败，基于LLM知识回答\n",
        "        fallback_prompt = f\"\"\"搜索API暂时不可用，请基于您的知识回答用户的问题：\n",
        "\n",
        "用户问题：{state['user_query']}\n",
        "\n",
        "请提供一个有用的回答，并说明这是基于已有知识的回答。\"\"\"\n",
        "\n",
        "        response = llm.invoke([SystemMessage(content=fallback_prompt)])\n",
        "\n",
        "        return {\n",
        "            \"final_answer\": response.content,\n",
        "            \"step\": \"completed\",\n",
        "            \"messages\": [AIMessage(content=response.content)]\n",
        "        }\n",
        "\n",
        "    # 基于搜索结果生成答案\n",
        "    answer_prompt = f\"\"\"基于以下搜索结果为用户提供完整、准确的答案：\n",
        "\n",
        "用户问题：{state['user_query']}\n",
        "\n",
        "搜索结果：\n",
        "{state['search_results']}\n",
        "\n",
        "请要求：\n",
        "1. 综合搜索结果，提供准确、有用的回答\n",
        "2. 如果是技术问题，提供具体的解决方案或代码\n",
        "3. 引用重要信息的来源\n",
        "4. 回答要结构清晰、易于理解\n",
        "5. 如果搜索结果不够完整，请说明并提供补充建议\"\"\"\n",
        "\n",
        "    response = llm.invoke([SystemMessage(content=answer_prompt)])\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": response.content,\n",
        "        \"step\": \"completed\",\n",
        "        \"messages\": [AIMessage(content=response.content)]\n",
        "    }"
      ],
      "metadata": {
        "id": "7mHS2_6PgZju"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 构建图"
      ],
      "metadata": {
        "id": "0vSgBha-gyAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "def create_search_assistant():\n",
        "    workflow = StateGraph(SearchState)\n",
        "\n",
        "    # 添加三个节点\n",
        "    workflow.add_node(\"understand\", understand_query_node)\n",
        "    workflow.add_node(\"search\", tavily_search_node)\n",
        "    workflow.add_node(\"answer\", generate_answer_node)\n",
        "\n",
        "    # 设置线性流程\n",
        "    workflow.add_edge(START, \"understand\")\n",
        "    workflow.add_edge(\"understand\", \"search\")\n",
        "    workflow.add_edge(\"search\", \"answer\")\n",
        "    workflow.add_edge(\"answer\", END)\n",
        "\n",
        "    # 编译图\n",
        "    memory = InMemorySaver()\n",
        "    app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "    return app\n"
      ],
      "metadata": {
        "id": "Ffr9moJJgz7k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"主函数：运行智能搜索助手\"\"\"\n",
        "\n",
        "# 检查API密钥\n",
        "if not os.getenv(\"TAVILY_API_KEY\"):\n",
        "    print(\"❌ 错误：请在.env文件中配置TAVILY_API_KEY\")\n",
        "    exit\n",
        "\n",
        "\n",
        "app = create_search_assistant()\n",
        "\n",
        "print(\"🔍 智能搜索助手启动！\")\n",
        "print(\"我会使用Tavily API为您搜索最新、最准确的信息\")\n",
        "print(\"支持各种问题：新闻、技术、知识问答等\")\n",
        "print(\"(输入 'quit' 退出)\\n\")\n",
        "\n",
        "session_count = 0\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"🤔 您想了解什么: \").strip()\n",
        "\n",
        "    if user_input.lower() in ['quit', 'q', '退出', 'exit']:\n",
        "        print(\"感谢使用！再见！👋\")\n",
        "        break\n",
        "\n",
        "    if not user_input:\n",
        "        continue\n",
        "\n",
        "    session_count += 1\n",
        "    config = {\"configurable\": {\"thread_id\": f\"search-session-{session_count}\"}}\n",
        "\n",
        "    # 初始状态\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=user_input)],\n",
        "        \"user_query\": \"\",\n",
        "        \"search_query\": \"\",\n",
        "        \"search_results\": \"\",\n",
        "        \"final_answer\": \"\",\n",
        "        \"step\": \"start\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "        # 执行工作流\n",
        "        async for output in app.astream(initial_state, config=config):\n",
        "            for node_name, node_output in output.items():\n",
        "                if \"messages\" in node_output and node_output[\"messages\"]:\n",
        "                    latest_message = node_output[\"messages\"][-1]\n",
        "                    if isinstance(latest_message, AIMessage):\n",
        "                        if node_name == \"understand\":\n",
        "                            print(f\"🧠 理解阶段: {latest_message.content}\")\n",
        "                        elif node_name == \"search\":\n",
        "                            print(f\"🔍 搜索阶段: {latest_message.content}\")\n",
        "                        elif node_name == \"answer\":\n",
        "                            print(f\"\\n💡 最终回答:\\n{latest_message.content}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 发生错误: {e}\")\n",
        "        print(\"请重新输入您的问题。\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6pZNHdualzq",
        "outputId": "430076a8-c119-4167-9396-a9df03ae9a19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 智能搜索助手启动！\n",
            "我会使用Tavily API为您搜索最新、最准确的信息\n",
            "支持各种问题：新闻、技术、知识问答等\n",
            "(输入 'quit' 退出)\n",
            "\n",
            "🤔 您想了解什么: 明天我要去北京，天气怎么样？有合适的景点吗\n",
            "\n",
            "============================================================\n",
            "🧠 理解阶段: 我理解您的需求：理解：用户需要了解北京明天的天气预报以及推荐的旅游景点。\n",
            "搜索词：北京明天天气 北京旅游景点推荐\n",
            "🔍 正在搜索: 北京明天天气 北京旅游景点推荐\n",
            "🔍 搜索阶段: ✅ 搜索完成！找到了相关信息，正在为您整理答案...\n",
            "\n",
            "💡 最终回答:\n",
            "根据您的需求，我为您整理了北京明天的天气预报和一些热门的旅游景点推荐。\n",
            "\n",
            "### 北京明天天气预报\n",
            "\n",
            "- **天气状况**：小雨\n",
            "- **气温**：12°C ~ 14°C\n",
            "\n",
            "**温馨提示**：明天北京有雨，气温较低。出行请务必携带雨具，并注意添加衣物，保暖防寒。\n",
            "\n",
            "### 北京旅游景点推荐\n",
            "\n",
            "以下是北京一些最受欢迎且经典的旅游景点，供您参考规划行程：\n",
            "\n",
            "#### 1. 故宫 (紫禁城)\n",
            "- **简介**：明清两代的皇家宫殿，是世界上现存规模最大、保存最为完整的木质结构古建筑群之一。\n",
            "- **游玩建议**：漫步于北京中轴线上，欣赏精妙绝伦的宫殿建筑，领略皇家气派。建议聆听讲解，了解紫禁城的历史故事。\n",
            "- **参考门票**：旺季60元/人；淡季40元/人。\n",
            "- **开放时间**：旺季(4月1日~10月31日) 8:30~17:00；淡季 8:30~16:30。\n",
            "\n",
            "> 信息来源：[北京旅游攻略必去景点推荐](https://www.tibetcn.com/wenda/279.html)\n",
            "\n",
            "#### 2. 慕田峪长城\n",
            "- **简介**：长城中以其秀丽的景色和险要的走势而闻名的一段，相比八达岭人流量可能稍少一些。\n",
            "- **游玩建议**：体验“不到长城非好汉”的豪情，欣赏壮丽的山川风光。\n",
            "- **最佳旅游时间**：4月-5月，9月-10月。\n",
            "\n",
            "> 信息来源：[北京旅游攻略必去景点推荐](https://www.tibetcn.com/wenda/279.html)\n",
            "\n",
            "#### 3. 天坛\n",
            "- **简介**：明清皇帝祭天、祈谷的场所，建筑精巧，是中国古代祭祀建筑的典范。\n",
            "- **游玩建议**：重点参观圜丘坛和祈年殿，了解古代祭祀文化。别忘了体验回音壁的神奇声学现象。\n",
            "- **参考门票**：旺季15元/人；淡季10元/人。\n",
            "- **开放时间**：旺季6:00~22:00；淡季6:30~22:00。\n",
            "\n",
            "> 信息来源：[北京旅游攻略必去景点推荐](https://www.tibetcn.com/wenda/279.html)\n",
            "\n",
            "#### 4. 颐和园\n",
            "- **简介**：清朝的皇家行宫和大型园林，以昆明湖、万寿山为基址，汲取江南园林设计手法建成。\n",
            "- **游玩建议**：漫步于亭台楼阁、寺庙桥梁之间，或乘船游览昆明湖，感受皇家园林的秀美与宁静。\n",
            "- **参考门票**：旺季30元/人；淡季20元/人。\n",
            "- **开放时间**：旺季6:00~20:00；淡季6:30~19:00。\n",
            "\n",
            "> 信息来源：[北京旅游攻略必去景点推荐](https://www.tibetcn.com/wenda/279.html)\n",
            "\n",
            "#### 5. 天安门广场\n",
            "- **简介**：世界上最大的城市广场，是中国的象征之一。\n",
            "- **游玩建议**：广场适合散步游览，观看庄严的升旗仪式，参观天安门城楼和中国国家博物馆。\n",
            "\n",
            "> 信息来源：[北京旅游攻略必去景点推荐](https://www.tibetcn.com/wenda/279.html)\n",
            "\n",
            "### 补充建议\n",
            "\n",
            "1.  **行程规划**：由于明天有雨，建议优先安排室内活动或受天气影响较小的景点，例如故宫（宫殿内）、国家博物馆等。长城、颐和园等户外景点若在雨天游览，体验可能会打折扣，且需特别注意安全。\n",
            "2.  **门票预订**：热门景点（尤其是故宫）门票紧俏，强烈建议您提前在官方网站或授权的在线旅游平台进行实名预约购票。\n",
            "3.  **交通出行**：雨天路面湿滑，可能会加剧交通拥堵。建议您预留充足的出行时间，并优先选择地铁等公共交通方式。\n",
            "\n",
            "希望以上信息能帮助您更好地规划明天的北京之行！祝您旅途愉快！\n",
            "\n",
            "============================================================\n",
            "\n",
            "🤔 您想了解什么: quit\n",
            "感谢使用！再见！👋\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlZqW8YKigiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}